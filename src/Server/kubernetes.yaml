# Persistent Volume Claim for output files
# More Info: https://docs.microsoft.com/en-us/azure/aks/azure-files-dynamic-pv
# Note: will be made available through kubectl get pvc
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-rw-output
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
  storageClassName: azurefile

---
# Simulation Cluster Deployment
apiVersion: apps/v1
kind: Deployment # Create Dapr Deployment, will automatically have 2 pods (described below + daprd)
metadata:
  name: rw-server
  labels: # Labels for the DEPLOYMENT, this way we can filter e.g. `kubectl delete -l key=value,key2=value2`
    app: rw-server # deployment-roadwork-...
spec:
  replicas: 2
  selector:
    matchLabels:
     app: actoropenai # Which pod will the deployment apply to?
  template:
    metadata:
      labels: # Labels for the POD
        app: actoropenai # pod-roadwork-...
      annotations:
        dapr.io/enabled: "true" # Do we inject a sidecar to this deployment?
        dapr.io/id: "actoropenai" # Unique ID or Name for Dapr App (so we can communicate with it)
        dapr.io/port: "3000" # Port we are going to listen on (is app specific)
    spec:
      containers:
      - name: server # Name of our container, e.g. `kubectl logs -c c-rw-...`
        image: roadwork/rw-server
        imagePullPolicy: Always # in production PullIfNotPresent or Always
        ports:
        - containerPort: 3000
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        volumeMounts:
        - mountPath: "/mnt/rw-output"
          name: volume-rw-output
      volumes:
        - name: volume-rw-output
          persistentVolumeClaim:
            claimName: pvc-rw-output